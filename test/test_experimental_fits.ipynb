{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import importlib\n",
    "import src.assay_calibration.fit_utils.two_sample.fit\n",
    "from src.assay_calibration.fit_utils.fit import Fit\n",
    "importlib.reload(src.assay_calibration.fit_utils.two_sample.fit)\n",
    "importlib.reload(src.assay_calibration.fit_utils.fit)\n",
    "from src.assay_calibration.fit_utils.two_sample.fit import single_fit\n",
    "from src.assay_calibration.fit_utils.two_sample import (density_utils,constraints, optimize)\n",
    "import scipy.stats as sps\n",
    "import matplotlib\n",
    "matplotlib.set_loglevel(\"warning\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "import os\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "from src.assay_calibration.data_utils.dataset import (\n",
    "    PillarProjectDataframe,\n",
    "    Scoreset,\n",
    "    BasicScoreset,\n",
    ")\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit(ds, component_range, check_monotonic, init_strategy):\n",
    "    # Load directly from JSON\n",
    "    fit = Fit(ds)\n",
    "    fits, _, _ = fit.run(\n",
    "                core_limit=10,\n",
    "                num_fits=20,\n",
    "                verbose_level=20,\n",
    "                component_range=component_range,\n",
    "                bootstrap=False,\n",
    "                verbose=False,\n",
    "                max_em_iters=10000,\n",
    "                check_convergence=False,\n",
    "                check_monotonic=check_monotonic,\n",
    "                # submerge_steps=None,#256 if check_monotonic else None,\n",
    "                init_strategy=init_strategy,\n",
    "                score_min=ds.scores.min() - 1,\n",
    "                score_max=ds.scores.max() + 1,\n",
    "                init_constraint_adjustment_param=\"skew\",\n",
    "                # kmean_init=\"k-means++\"\n",
    "            )\n",
    "    \n",
    "    return fits, ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing DDX3X_Radford_2023_cLFC_day15\n",
      "DDX3X_Radford_2023_cLFC_day15: 9080 total variants\n",
      "\tPathogenic/Likely Pathogenic: 201 variants\n",
      "\tBenign/Likely Benign: 88 variants\n",
      "\tgnomAD: 524 variants\n",
      "\tSynonymous: 1245 variants\n",
      "\tAll Missense SNV: 4380 variants\n",
      "\n",
      "DDX3X_Radford_2023_cLFC_day15 2-component constraint [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "DDX3X_Radford_2023_cLFC_day15 2-component no constraint [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "DDX3X_Radford_2023_cLFC_day15 3-component constraint [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "DDX3X_Radford_2023_cLFC_day15 3-component no constraint [[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n",
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_5sample/DDX3X_Radford_2023_cLFC_day15.png\n",
      "All plots saved!\n"
     ]
    }
   ],
   "source": [
    "#### import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"/data/ross/assay_calibration/test_experimental_plots_v12\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Suppress matplotlib debug messages\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "n_non_violating_fits_without_constraint = 0\n",
    "# start = False\n",
    "\n",
    "dataset_fs = glob.glob(\"/data/ross/assay_calibration/scoresets/DDX*_missense_replace_gnomad_modified*.json\")\n",
    "# dataset_fs = [f for f in dataset_fs if \"_missense_replace_gnomad_modified\" not in f]\n",
    "for dataset_f in (dataset_fs):\n",
    "    \n",
    "    dataset_name = dataset_f.split('/')[-1][:-5]\n",
    "    # if dataset_name == \"HMBS_van_Loggerenberg_2023_combined\":\n",
    "    #     start = True\n",
    "    # if not start:\n",
    "    #     continue\n",
    "    \n",
    "    print(f\"Processing {dataset_name}\")\n",
    "\n",
    "    ds = Scoreset.from_json(dataset_f, five_sample=True)\n",
    "    print(ds)\n",
    "\n",
    "    sample_names = np.array([sample[1] for sample in ds.samples])\n",
    "    \n",
    "    # Create figure with 4x3 subplot grid\n",
    "    fig, axes = plt.subplots(len(sample_names), 4, figsize=(18, 5*len(sample_names)))\n",
    "    fig.suptitle(f'Dataset: {dataset_name}', fontsize=16, y=0.995)\n",
    "\n",
    "    all_results[dataset_name] = {}\n",
    "    \n",
    "    plot_idx = 0\n",
    "    for component_range in [\"2-component\", \"3-component\"]:\n",
    "        for monotonicity_constraint in [\"constraint\", \"no constraint\"]:\n",
    "            # for init_density_fix in [\"lambda\",\"sigma\"]:\n",
    "            init_strategy = \"random\"\n",
    "            \n",
    "            # Run the fit\n",
    "            try:\n",
    "                fits, ds = test_fit(\n",
    "                    ds, \n",
    "                    component_range=[3] if component_range[0] == \"3\" else [2], \n",
    "                    check_monotonic=False if monotonicity_constraint[0] == \"n\" else True, \n",
    "                    init_strategy=init_strategy\n",
    "                )\n",
    "                \n",
    "                # Get best fit\n",
    "                # print(fits[0])\n",
    "                fit_results = sorted(fits, key=lambda res: res['likelihoods'][-1], reverse=True)\n",
    "                times_submerged = [results['times_submerged'] for results in fit_results]\n",
    "                print(dataset_name, component_range, monotonicity_constraint, times_submerged)\n",
    "                best_fit = fit_results[0]\n",
    "                best_init = \"MoM\" if best_fit['kmeans'] == \"method_of_moments\" else \"KM\"\n",
    "                xlims = best_fit['xlims']\n",
    "                scores = ds.scores\n",
    "                sample_assignments = ds.sample_assignments\n",
    "\n",
    "                \n",
    "                all_results[dataset_name][(component_range, monotonicity_constraint)] = fit_results \n",
    "    \n",
    "                # Calculate densities\n",
    "                score_range = np.linspace(scores.min(), scores.max(), 1000)\n",
    "                estimatedDensities = np.array([\n",
    "                    density_utils.joint_densities(\n",
    "                        score_range[..., None],\n",
    "                        best_fit['component_params'],\n",
    "                        sample_weights\n",
    "                    ).squeeze() for sample_weights in best_fit['weights']\n",
    "                ])\n",
    "                \n",
    "                # Check if density constraint violated\n",
    "                fit_violates_constraint = constraints.multicomponent_density_constraint_violated(best_fit['component_params'], xlims)\n",
    "                if monotonicity_constraint == \"no constraint\" and fit_violates_constraint:\n",
    "                    n_non_violating_fits_without_constraint += 1\n",
    "                fit_violates_constraint = \"violates\" if fit_violates_constraint else \"not violates\"\n",
    "\n",
    "                sample_lls = density_utils.get_sample_likelihood(scores, sample_assignments, best_fit['component_params'], best_fit['weights']) / np.array([sum(each_sample_assignments) for each_sample_assignments in sample_assignments.T])\n",
    "                \n",
    "                # Plot for each sample (3 columns)\n",
    "                for i in range(len(estimatedDensities)):\n",
    "                    ax = axes[i, plot_idx]\n",
    "    \n",
    "                    \n",
    "                    # Plot estimated density\n",
    "                    ax.plot(score_range, estimatedDensities[i].sum(0), \n",
    "                           label='Estimated', color='C1', linestyle='-', linewidth=2)\n",
    "                    \n",
    "                    # Plot histogram of actual data\n",
    "                    max_hist_height = 1.0\n",
    "                    if i < sample_assignments.shape[1] and sample_assignments[:, i].sum() > 0:\n",
    "                        sample_data = scores[sample_assignments[:, i]]\n",
    "                        counts, bins, patches = ax.hist(sample_data, \n",
    "                                                        bins=30, density=True, alpha=0.3, \n",
    "                                                        color='gray', label='Data')\n",
    "                        \n",
    "                        # Get max height of histogram\n",
    "                        max_hist_height = counts.max()\n",
    "                        \n",
    "                        # Set ylim to 1.2x the histogram max to avoid components with 1e99 density and no scale\n",
    "                        ax.set_ylim(0, max_hist_height * 1.2)\n",
    "                    \n",
    "                    # Set labels and title\n",
    "                    if plot_idx == 0:\n",
    "                        ax.set_ylabel(sample_names[i], \n",
    "                                     fontsize=12, fontweight='bold')\n",
    "                    \n",
    "                    if i == 0:\n",
    "                        ax.set_title(f'{component_range}, {monotonicity_constraint}, {best_init}, {fit_violates_constraint}', fontsize=12)\n",
    "                    \n",
    "                    if i == len(estimatedDensities) - 1:\n",
    "                        ax.set_xlabel('Score', fontsize=10)\n",
    "                    \n",
    "                    ax.legend(loc='upper right', fontsize=8)\n",
    "                    ax.grid(True, alpha=0.2)\n",
    "                    \n",
    "                    # Add likelihood value as text\n",
    "                    likelihood = best_fit['likelihoods'][-1]\n",
    "                    ax.text(0.02, 0.98, f'SLL: {sample_lls[i]:.3f}, LL: {likelihood:.3f}, n={len(scores[sample_assignments[:, i]])}', \n",
    "                           transform=ax.transAxes, fontsize=12,\n",
    "                           verticalalignment='top')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error with {component_range}, {monotonicity_constraint}: {e}\")\n",
    "                # Create empty plots with error message\n",
    "                for i in range(len(estimatedDensities)):\n",
    "                    ax = axes[i, plot_idx]\n",
    "                    ax.text(0.5, 0.5, f'Error:\\n{str(e)[:30]}...', \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "\n",
    "                    if i == 0:\n",
    "                        ax.set_title(f'{component_range}, {monotonicity_constraint}, {best_init}, {fit_violates_constraint}', fontsize=12)\n",
    "                    \n",
    "                    if plot_idx == 0:\n",
    "                        ax.set_ylabel(sample_names[i], \n",
    "                                     fontsize=12, fontweight='bold')\n",
    "                    \n",
    "                    if i == len(estimatedDensities) - 1:\n",
    "                        ax.set_xlabel('Score', fontsize=10)\n",
    "            \n",
    "            plot_idx += 1\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    \n",
    "    output_path = f\"{output_dir}/{dataset_name}.png\"\n",
    "    plt.savefig(output_path, dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Saved to {output_path}\")\n",
    "\n",
    "print(\"All plots saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (assay_calibration)",
   "language": "python",
   "name": "assay_calibration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
