{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import importlib\n",
    "import src.assay_calibration.fit_utils.two_sample.fit\n",
    "from src.assay_calibration.fit_utils.fit import Fit\n",
    "importlib.reload(src.assay_calibration.fit_utils.two_sample.fit)\n",
    "importlib.reload(src.assay_calibration.fit_utils.fit)\n",
    "from src.assay_calibration.fit_utils.two_sample.fit import single_fit\n",
    "from src.assay_calibration.fit_utils.two_sample import (density_utils,constraints, optimize)\n",
    "import scipy.stats as sps\n",
    "import matplotlib\n",
    "matplotlib.set_loglevel(\"warning\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "import os\n",
    "sys.path.append(str(Path(os.getcwd()).parent))\n",
    "from src.assay_calibration.data_utils.dataset import (\n",
    "    PillarProjectDataframe,\n",
    "    Scoreset,\n",
    "    BasicScoreset,\n",
    ")\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fit(ds, component_range, check_monotonic, init_strategy):\n",
    "    # Load directly from JSON\n",
    "    fit = Fit(ds)\n",
    "    fits = fit.run(\n",
    "                core_limit=20,\n",
    "                num_fits=20,\n",
    "                verbose_level=20,\n",
    "                component_range=component_range,\n",
    "                bootstrap=False,\n",
    "                verbose=False,\n",
    "                max_em_iters=10000,\n",
    "                check_convergence=False,\n",
    "                check_monotonic=check_monotonic,\n",
    "                init_strategy=init_strategy,\n",
    "                score_min=ds.scores.min() - 1,\n",
    "                score_max=ds.scores.max() + 1,\n",
    "                # kmean_init=\"k-means++\"\n",
    "            )\n",
    "    \n",
    "    return fits, ds\n",
    "\n",
    "# for dataset_f in glob.glob(\"/data/ross/assay_calibration/scoresets/*.json\"):\n",
    "    \n",
    "#     dataset_name = dataset_f.split('/')[-1][:-5]\n",
    "\n",
    "#     for component_range in (\"2-component\",\"3-component\"):\n",
    "#         for monotonicity_contraint in (\"no constraint\",\"constraint\"):\n",
    "#             # for init_strategy in (\"kmeans\",\"random\"):\n",
    "#             init_strategy = \"kmeans\"\n",
    "            \n",
    "#             fits, ds = test_fit(dataset_f, component_range=[3] if component_range[0] == \"3\" else [2], \n",
    "#                                 check_monotonic=False if monotonicity_contraint[0] == \"n\" else True, \n",
    "#                                 init_strategy=init_strategy)\n",
    "            \n",
    "#             fit_results = sorted(fits, key=lambda res: res['likelihoods'][-1], reverse=True)\n",
    "#             best_fit = fit_results[0]\n",
    "#             scores = ds.scores\n",
    "#             sample_assignments = ds.sample_assignments\n",
    "            \n",
    "#             score_range = np.linspace(scores.min(), scores.max(), 1000)\n",
    "#             estimatedDensities = np.array([density_utils.joint_densities(score_range[...,None],\n",
    "#                                                                          best_fit['component_params'],\n",
    "#                                                                          sample_weights).squeeze() for sample_weights in best_fit['weights']])\n",
    "            \n",
    "#             fig,ax = plt.subplots(3,1, figsize=(12,12))\n",
    "#             for i in range(3):\n",
    "#                 ax[i].plot(score_range, estimatedDensities[i].sum(0), label='Estimated', color='C1', linestyle='--')\n",
    "#                 ax[i].hist(scores[sample_assignments[:,i]], density=True, alpha=0.3, color='gray', label='Data histogram')\n",
    "#                 ax[i].set_title(f'Sample {i+1}')\n",
    "#                 ax[i].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ASPA_Grønbæk-Thygesen_2024_abundance\n",
      "ASPA_Grønbæk-Thygesen_2024_abundance: 18623 total variants\n",
      "\tPathogenic/Likely Pathogenic: 64 variants\n",
      "\tBenign/Likely Benign: 6 variants\n",
      "\tgnomAD: 352 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         ]��████████▌| 9613/10000 [01:07<00:02, 137.18it/s, likelihood=0.254291]|█████████▋| 9660/10000 [01:10<00:02, 135.41it/s, likelihood=0.244266]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/ASPA_Grønbæk-Thygesen_2024_abundance.png\n",
      "Processing ASPA_Grønbæk-Thygesen_2024_toxicity\n",
      "ASPA_Grønbæk-Thygesen_2024_toxicity: 18615 total variants\n",
      "\tPathogenic/Likely Pathogenic: 64 variants\n",
      "\tBenign/Likely Benign: 6 variants\n",
      "\tgnomAD: 352 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        7][00:08<00:42, 195.88it/s, likelihood=0.610778]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/ASPA_Grønbæk-Thygesen_2024_toxicity.png\n",
      "Processing BAP1_Waters_2024\n",
      "BAP1_Waters_2024: 18108 total variants\n",
      "\tPathogenic/Likely Pathogenic: 197 variants\n",
      "\tBenign/Likely Benign: 398 variants\n",
      "\tgnomAD: 1369 variants\n",
      "\tSynonymous: 1854 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BAP1_Waters_2024.png\n",
      "Processing BARD1_unpublished\n",
      "BARD1_unpublished: 9128 total variants\n",
      "\tPathogenic/Likely Pathogenic: 185 variants\n",
      "\tBenign/Likely Benign: 270 variants\n",
      "\tgnomAD: 1614 variants\n",
      "\tSynonymous: 1337 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       ]]01:15, 103.28it/s, likelihood=2.245437]teration:  24%|██▍       | 2420/10000 [00:23<01:13, 103.68it/s, likelihood=2.245437]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BARD1_unpublished.png\n",
      "Processing BRCA1_Adamovich_2022_Cisplatin\n",
      "BRCA1_Adamovich_2022_Cisplatin: 5131 total variants\n",
      "\tPathogenic/Likely Pathogenic: 55 variants\n",
      "\tBenign/Likely Benign: 25 variants\n",
      "\tgnomAD: 115 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         ]]99.81it/s, likelihood=-0.574035]█████████▊| 9854/10000 [01:08<00:01, 136.52it/s, likelihood=-0.610467].39it/s, likelihood=-0.610764]�██████▊| 9862/10000 [01:09<00:01, 96.60it/s, likelihood=-0.610461]█████████▉| 9913/10000 [01:09<00:00, 122.39it/s, likelihood=-0.623184]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA1_Adamovich_2022_Cisplatin.png\n",
      "Processing BRCA1_Adamovich_2022_HDR\n",
      "BRCA1_Adamovich_2022_HDR: 8122 total variants\n",
      "\tPathogenic/Likely Pathogenic: 58 variants\n",
      "\tBenign/Likely Benign: 34 variants\n",
      "\tgnomAD: 149 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         ]]52.26it/s, likelihood=-0.481833]�| 9650/10000 [01:09<00:02, 132.48it/s, likelihood=-0.435636]��█████▉| 9897/10000 [01:11<00:00, 133.73it/s, likelihood=-0.435635]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA1_Adamovich_2022_HDR.png\n",
      "Processing BRCA1_Findlay_2018\n",
      "BRCA1_Findlay_2018: 3893 total variants\n",
      "\tPathogenic/Likely Pathogenic: 410 variants\n",
      "\tBenign/Likely Benign: 270 variants\n",
      "\tgnomAD: 599 variants\n",
      "\tSynonymous: 544 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        0]00:14<01:31, 93.84it/s, likelihood=-0.611221]teration:  25%|██▍       | 2483/10000 [00:26<01:20, 93.88it/s, likelihood=-0.611220]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA1_Findlay_2018.png\n",
      "Processing BRCA2_Hu_2024\n",
      "BRCA2_Hu_2024: 444 total variants\n",
      "\tPathogenic/Likely Pathogenic: 48 variants\n",
      "\tBenign/Likely Benign: 44 variants\n",
      "\tgnomAD: 235 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         6]   | 1750/10000 [00:09<00:41, 197.27it/s, likelihood=-1.187771]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA2_Hu_2024.png\n",
      "Processing BRCA2_Sahu_2023_exon13_Cisplatin\n",
      "BRCA2_Sahu_2023_exon13_Cisplatin: 251 total variants\n",
      "\tPathogenic/Likely Pathogenic: 17 variants\n",
      "\tBenign/Likely Benign: 9 variants\n",
      "\tgnomAD: 46 variants\n",
      "\tSynonymous: 39 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EM Iteration:   8%|▊         | 825/10000 [00:06<01:11, 128.93it/s, likelihood=0.005170]] 8]10000 [01:05<00:00, 74.58it/s, likelihood=-0.079733]��█████▉| 9931/10000 [01:05<00:00, 120.24it/s, likelihood=-0.079734]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with 3-component, no constraint: Likelihood decreased at iteration 702 for unconstrained fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA2_Sahu_2023_exon13_Cisplatin.png\n",
      "Processing BRCA2_Sahu_2023_exon13_Olaparib\n",
      "BRCA2_Sahu_2023_exon13_Olaparib: 251 total variants\n",
      "\tPathogenic/Likely Pathogenic: 17 variants\n",
      "\tBenign/Likely Benign: 9 variants\n",
      "\tgnomAD: 46 variants\n",
      "\tSynonymous: 39 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA2_Sahu_2023_exon13_Olaparib.png\n",
      "Processing BRCA2_Sahu_2023_exon13_SGE\n",
      "BRCA2_Sahu_2023_exon13_SGE: 251 total variants\n",
      "\tPathogenic/Likely Pathogenic: 17 variants\n",
      "\tBenign/Likely Benign: 9 variants\n",
      "\tgnomAD: 46 variants\n",
      "\tSynonymous: 39 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EM Iteration:  20%|█▉        | 1951/10000 [00:14<01:00, 132.55it/s, likelihood=0.087004]1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Error with 3-component, no constraint: Likelihood decreased at iteration 1777 for unconstrained fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA2_Sahu_2023_exon13_SGE.png\n",
      "Processing BRCA2_Sahu_2023_exon13_global_score\n",
      "BRCA2_Sahu_2023_exon13_global_score: 251 total variants\n",
      "\tPathogenic/Likely Pathogenic: 17 variants\n",
      "\tBenign/Likely Benign: 9 variants\n",
      "\tgnomAD: 46 variants\n",
      "\tSynonymous: 39 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         ]].95it/s, likelihood=-0.029066]ood=-0.032956]��█████▉| 9991/10000 [01:04<00:00, 130.68it/s, likelihood=-0.029061]98.07it/s, likelihood=-0.032952]███▊| 9862/10000 [01:20<00:01, 117.92it/s, likelihood=0.035077]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved to /data/ross/assay_calibration/test_experimental_plots_v3/BRCA2_Sahu_2023_exon13_global_score.png\n",
      "Processing BRCA2_Sahu_2025_HDR\n",
      "BRCA2_Sahu_2025_HDR: 6550 total variants\n",
      "\tPathogenic/Likely Pathogenic: 353 variants\n",
      "\tBenign/Likely Benign: 71 variants\n",
      "\tgnomAD: 938 variants\n",
      "\tSynonymous: 1276 variants\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EM Iteration:  14%|█▍        | 1424/10000 [00:17<01:44, 82.17it/s, likelihood=-0.879044] "
     ]
    }
   ],
   "source": [
    "#### import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = \"/data/ross/assay_calibration/test_experimental_plots_v3\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Suppress matplotlib debug messages\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "\n",
    "for dataset_f in glob.glob(\"/data/ross/assay_calibration/scoresets/*.json\"):\n",
    "    \n",
    "    dataset_name = dataset_f.split('/')[-1][:-5]\n",
    "    print(f\"Processing {dataset_name}\")\n",
    "\n",
    "    ds = Scoreset.from_json(dataset_f)\n",
    "    print(ds)\n",
    "    \n",
    "    # Create figure with 4x3 subplot grid\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(18, 20))\n",
    "    fig.suptitle(f'Dataset: {dataset_name}', fontsize=16, y=0.995)\n",
    "    \n",
    "    plot_idx = 0\n",
    "    for component_range in (\"2-component\", \"3-component\"):\n",
    "        for monotonicity_constraint in (\"no constraint\", \"constraint\"):\n",
    "            init_strategy = \"random\"\n",
    "            \n",
    "            # Run the fit\n",
    "            try:\n",
    "                fits, ds = test_fit(\n",
    "                    ds, \n",
    "                    component_range=[3] if component_range[0] == \"3\" else [2], \n",
    "                    check_monotonic=False if monotonicity_constraint[0] == \"n\" else True, \n",
    "                    init_strategy=init_strategy\n",
    "                )\n",
    "                \n",
    "                # Get best fit\n",
    "                fit_results = sorted(fits, key=lambda res: res['likelihoods'][-1], reverse=True)\n",
    "                best_fit = fit_results[0]\n",
    "                best_init = \"MoM\" if best_fit['kmeans'] == \"method_of_moments\" else \"KM\"\n",
    "                scores = ds.scores\n",
    "                sample_assignments = ds.sample_assignments\n",
    "                \n",
    "                # Calculate densities\n",
    "                score_range = np.linspace(scores.min(), scores.max(), 1000)\n",
    "                estimatedDensities = np.array([\n",
    "                    density_utils.joint_densities(\n",
    "                        score_range[..., None],\n",
    "                        best_fit['component_params'],\n",
    "                        sample_weights\n",
    "                    ).squeeze() for sample_weights in best_fit['weights']\n",
    "                ])\n",
    "                \n",
    "                # Plot for each sample (3 columns)\n",
    "                for i in range(3):\n",
    "                    ax = axes[plot_idx, i]\n",
    "                    \n",
    "                    # Plot estimated density\n",
    "                    ax.plot(score_range, estimatedDensities[i].sum(0), \n",
    "                           label='Estimated', color='C1', linestyle='-', linewidth=2)\n",
    "                    \n",
    "                    # Plot histogram of actual data\n",
    "                    if i < sample_assignments.shape[1] and sample_assignments[:, i].sum() > 0:\n",
    "                        ax.hist(scores[sample_assignments[:, i]], \n",
    "                               bins=30, density=True, alpha=0.3, \n",
    "                               color='gray', label='Data')\n",
    "                    \n",
    "                    # Set labels and title\n",
    "                    if i == 0:\n",
    "                        ax.set_ylabel(f'{component_range}, {monotonicity_constraint}, {best_init}', \n",
    "                                     fontsize=10, fontweight='bold')\n",
    "                    \n",
    "                    if plot_idx == 0:\n",
    "                        ax.set_title(f'Sample {i+1}', fontsize=12)\n",
    "                    \n",
    "                    if plot_idx == 3:\n",
    "                        ax.set_xlabel('Score', fontsize=10)\n",
    "                    \n",
    "                    ax.legend(loc='upper right', fontsize=8)\n",
    "                    ax.grid(True, alpha=0.2)\n",
    "                    \n",
    "                    # Add likelihood value as text\n",
    "                    likelihood = best_fit['likelihoods'][-1]\n",
    "                    ax.text(0.02, 0.98, f'LL: {likelihood:.3f}', \n",
    "                           transform=ax.transAxes, fontsize=8,\n",
    "                           verticalalignment='top')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  Error with {component_range}, {monotonicity_constraint}: {e}\")\n",
    "                # Create empty plots with error message\n",
    "                for i in range(3):\n",
    "                    ax = axes[plot_idx, i]\n",
    "                    ax.text(0.5, 0.5, f'Error:\\n{str(e)[:30]}...', \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "                    \n",
    "                    if i == 0:\n",
    "                        ax.set_ylabel(f'{component_range}, {monotonicity_constraint}, {best_init}', \n",
    "                                     fontsize=10, fontweight='bold')\n",
    "                    if plot_idx == 0:\n",
    "                        ax.set_title(f'Sample {i+1}', fontsize=12)\n",
    "            \n",
    "            plot_idx += 1\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.99])\n",
    "    \n",
    "    output_path = f\"{output_dir}/{dataset_name}.png\"\n",
    "    plt.savefig(output_path, dpi=100, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"  Saved to {output_path}\")\n",
    "\n",
    "print(\"All plots saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints.multicomponent_density_constraint_violated(best_fit['component_params'],\n",
    "                                                       score_range[[0,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit['component_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.min(),scores.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (assay_calibration)",
   "language": "python",
   "name": "assay_calibration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
