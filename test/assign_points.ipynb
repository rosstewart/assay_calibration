{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47c6006b-ab37-4c3b-8ba1-3a30666a0b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List\n",
    "from joblib import Parallel, delayed\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR)\n",
    "sys.path.append(\"..\")\n",
    "from src.assay_calibration.fit_utils.fit import (calculate_score_ranges,thresholds_from_prior)  # noqa: E402\n",
    "from src.assay_calibration.fit_utils.two_sample import density_utils  # noqa: E402\n",
    "from src.assay_calibration.data_utils.dataset import Scoreset  # noqa: E402\n",
    "from src.assay_calibration.fit_utils.utils import serialize_dict  # noqa: E402\n",
    "\n",
    "\n",
    "\n",
    "def summarize_scoreset(fits,scoreset,save_filepath, **kwargs):\n",
    "    \"\"\"\n",
    "    Summarizes a scoreset based on the provided arguments.\n",
    "    Args:\n",
    "        args: An object containing the following attributes:\n",
    "            - fits (List[Dict]) : List of fit results\n",
    "            - scoreset_name (str) : Name of the scoreset to summarize\n",
    "            - df (pandas.DataFrame, optional): A pandas DataFrame to be summarized. \n",
    "              If provided, this will be used directly.\n",
    "            - pillar_df_filepath (str, optional): A file path to a CSV file. If `df` \n",
    "              is not provided, the CSV file at this path will be read into a pandas \n",
    "              DataFrame and used for summarization.\n",
    "    Optional Keyword Args:\n",
    "        - point_values (List[int], optional): List of point values to assign. Defaults to \n",
    "          [1,2,3,4,5,6,7,8].\n",
    "        - pathogenic_idx (int, optional): Index of the pathogenic component. Defaults to 0.\n",
    "        - benign_idx (int, optional): Index of the benign component. Defaults to 1.\n",
    "        - tolerance (float, optional): Tolerance for convergence in prior estimation. Defaults to 1e-4.\n",
    "        - max_em_steps (int, optional): Maximum number of EM steps for prior estimation. Defaults to 10000.\n",
    "\n",
    "    Note:\n",
    "        Either `df` or `pillar_df_filepath` must be provided in `args`. If both are \n",
    "        provided, `df` takes precedence.\n",
    "    \"\"\"\n",
    "    priors, point_ranges, score_range, log_fp, log_fb, all_path_ranges, all_ben_ranges = process_fits(fits,scoreset,)\n",
    "    results = dict(prior=np.nanmedian(priors),\n",
    "                   point_ranges=point_ranges,\n",
    "                   priors=priors,\n",
    "                   score_range=score_range,\n",
    "                   log_lr_plus=log_fp - log_fb,\n",
    "                   all_path_ranges=all_path_ranges,\n",
    "                   all_ben_ranges=all_ben_ranges)\n",
    "    results = serialize_dict(results)\n",
    "    save_filepath = Path(save_filepath)\n",
    "    save_filepath.parent.mkdir(exist_ok=True,parents=True)\n",
    "    with open(save_filepath,'w') as f:\n",
    "        json.dump(results,f,indent=2)\n",
    "    save_filepath_compact = save_filepath.parent / f\"{save_filepath.stem}_compact.json\"\n",
    "    with open(save_filepath_compact,'w') as f:\n",
    "        json.dump({k: results[k] for k in ['prior','point_ranges']},\n",
    "                  f,indent=2)\n",
    "    scoreset_fit_figure = plot_scoreset(scoreset, results, fits,score_range)\n",
    "    figure_filepath = save_filepath.parent / f\"{save_filepath.stem}figure_fits.png\"\n",
    "    scoreset_fit_figure.savefig(figure_filepath,bbox_inches='tight',dpi=300)\n",
    "    plt.close(scoreset_fit_figure) \n",
    "    summary_fig = plot_summary(scoreset, fits, results, score_range, log_fp, log_fb)\n",
    "    summary_figure_filepath = save_filepath.parent / f\"{save_filepath.stem}_figure_summary.png\"\n",
    "    summary_fig.savefig(summary_figure_filepath,bbox_inches='tight',dpi=300)\n",
    "    plt.close(summary_fig)\n",
    "\n",
    "def process_fits(fits, scoreset,**kwargs)->Tuple[np.ndarray,Dict[int,List[Tuple[float,float]]],np.ndarray,np.ndarray,np.ndarray,List[Dict[int,List[Tuple[float,float]]]],List[Dict[int,List[Tuple[float,float]]]]]:\n",
    "    n_cores = os.cpu_count() or 1\n",
    "    fit_priors = np.array(Parallel(n_jobs=min(len(fits), n_cores), verbose=10)(delayed(get_fit_prior)(fit, scoreset, **kwargs)\n",
    "                               for fit in fits))\n",
    "    point_values = kwargs.get('point_values',[1,2,3,4,5,6,7,8])\n",
    "    prior = np.nanmedian(fit_priors)\n",
    "    observed_scores = scoreset.scores[scoreset._sample_assignments.any(1)]\n",
    "    score_range = np.linspace(*np.percentile(observed_scores,[0,100]),10000) # type: ignore\n",
    "\n",
    "    _log_fp = np.stack([density_utils.mixture_pdf(score_range, _fit['fit']['component_params'],_fit['fit']['weights'][0])\n",
    "                        for _fit in fits])\n",
    "    _log_fb = np.stack([density_utils.mixture_pdf(score_range, _fit['fit']['component_params'],_fit['fit']['weights'][1])\n",
    "                       for _fit in fits])\n",
    "    log_fp = np.full((len(fits),len(score_range)),np.nan)\n",
    "    log_fb = np.full((len(fits),len(score_range)),np.nan)\n",
    "    ranges_pathogenic = []\n",
    "    ranges_benign = []\n",
    "    \n",
    "    for fitIdx,(fit, fp,fb) in enumerate(zip(fits, _log_fp,_log_fb)):\n",
    "        fit_xmin,fit_xmax = fit['fit']['xlims']\n",
    "        mask = (score_range >= fit_xmin) & (score_range <= fit_xmax)\n",
    "        log_fp[fitIdx,mask] = fp[mask]\n",
    "        log_fb[fitIdx,mask] = fb[mask]\n",
    "        lrP = log_fp[fitIdx,mask] - log_fb[fitIdx,mask]\n",
    "        s = score_range[mask]\n",
    "        ranges_p, ranges_b = calculate_score_ranges(lrP,lrP, fit_priors[fitIdx],s,\n",
    "                                                    point_values)\n",
    "        ranges_pathogenic.append(ranges_p)\n",
    "        ranges_benign.append(ranges_b)\n",
    "\n",
    "    log_lr_plus = log_fp - log_fb\n",
    "    nan_counts = np.isnan(log_lr_plus).sum(0)\n",
    "    range_subset = nan_counts < log_lr_plus.shape[0]\n",
    "    point_ranges = {}\n",
    "    if prior > 0 and prior < 1:\n",
    "        point_ranges_pathogenic, point_ranges_benign = calculate_score_ranges(np.nanpercentile(log_lr_plus[:,range_subset],\n",
    "                                                                                            5,axis=0),\n",
    "                                                                                np.nanpercentile(log_lr_plus[:,range_subset],\n",
    "                                                                                                95,axis=0),\n",
    "                                                                                prior,\n",
    "                                                                                score_range[range_subset],\n",
    "                                                                                point_values,)\n",
    "        point_ranges = {**point_ranges_pathogenic,**point_ranges_benign}\n",
    "    return fit_priors, point_ranges,score_range[range_subset],log_fp[:,range_subset], log_fb[:,range_subset], ranges_pathogenic, ranges_benign\n",
    "    \n",
    "\n",
    "\n",
    "def get_fit_prior(fit, scoreset,**kwargs):\n",
    "    pathogenic_idx = kwargs.get('pathogenic_idx',0)\n",
    "    benign_idx = kwargs.get('benign_idx',1)\n",
    "    params = fit['fit']['component_params']\n",
    "    weights = fit['fit']['weights']\n",
    "    population = scoreset.scores[scoreset._sample_assignments[:,2]]\n",
    "    pathogenic_density = density_utils.joint_densities(population,\n",
    "                                                       params,\n",
    "                                                       weights[pathogenic_idx]).sum(axis=0)\n",
    "    benign_density = density_utils.joint_densities(population,\n",
    "                                                       params,\n",
    "                                                       weights[benign_idx]).sum(axis=0)\n",
    "    assert len(pathogenic_density) == len(population)\n",
    "    assert len(benign_density) == len(population)\n",
    "    prior_estimate = 0.5\n",
    "    converged = False\n",
    "    em_steps = 0\n",
    "    max_em_steps = kwargs.get(\"max_em_steps\",10000)\n",
    "    while not converged:\n",
    "        em_steps += 1\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore', over='ignore',under='ignore'):\n",
    "            posteriors = 1 / (\n",
    "                1\n",
    "                + (1 - prior_estimate)\n",
    "                / prior_estimate\n",
    "                * benign_density # type: ignore\n",
    "                / pathogenic_density\n",
    "            )\n",
    "        new_prior = np.nanmean(posteriors)\n",
    "        prior_estimate = new_prior\n",
    "        if prior_estimate < 0 or prior_estimate > 1:\n",
    "            raise ValueError(f\"Invalid prior estimate obtained, {prior_estimate}\")\n",
    "        if em_steps >= max_em_steps:\n",
    "            break\n",
    "    return prior_estimate\n",
    "    \n",
    "def plot_scoreset(scoreset:Scoreset, summary: Dict, scoreset_fits: List[Dict], score_range):\n",
    "    fig, ax = plt.subplots(2,scoreset.n_samples, figsize=(5*scoreset.n_samples,10),sharex=True,sharey=False)\n",
    "    for sample_num in range(scoreset.n_samples):\n",
    "        sns.histplot(scoreset.scores[scoreset.sample_assignments[:,sample_num]],stat='density',ax=ax[1,sample_num],alpha=.5,color='pink',)\n",
    "        density = sample_density(score_range, scoreset_fits, sample_num)\n",
    "        for compNum in range(density.shape[1]):\n",
    "\n",
    "            compDensity = density[:,compNum,:]\n",
    "            d = np.nanpercentile(compDensity,[5,50,95],axis=0)\n",
    "            ax[1,sample_num].plot(score_range,d[1],color=f\"C{compNum}\",linestyle='--',label=f\"Comp {compNum+1}\")\n",
    "            ax[1,sample_num].legend()\n",
    "        d = np.nansum(density,axis=1)\n",
    "        d_perc = np.percentile(d,[5,50,95],axis=0)\n",
    "        ax[1,sample_num].plot(score_range,d_perc[1],color='black',alpha=.5)\n",
    "        ax[1,sample_num].fill_between(score_range,d_perc[0],d_perc[2],color='gray',alpha=0.3)\n",
    "        ax[1,sample_num].set_xlabel(\"Score\")\n",
    "        ax[0,sample_num].set_title(f\"{scoreset.sample_names[sample_num]} (n={scoreset.sample_assignments[:,sample_num].sum():,d})\")\n",
    "    point_ranges = sorted([(int(k), v) for k,v in summary['point_ranges'].items()])\n",
    "    point_values = [pr[0] for pr in point_ranges]\n",
    "    for axi in ax[0]:\n",
    "        for pointIdx,(pointVal, scoreRanges) in enumerate(point_ranges):\n",
    "            for sr in scoreRanges:\n",
    "                axi.plot([sr[0], sr[1]], [pointIdx,pointIdx], color='red' if pointVal > 0 else 'blue', linestyle='-', alpha=0.7)\n",
    "        axi.set_ylim(-1,len(point_values))\n",
    "        axi.set_ylabel(\"Points\")\n",
    "\n",
    "        axi.set_yticks(range(len(point_values)),labels=list(map(lambda i: f\"{i:+d}\" if i!=0 else \"0\",point_values)))\n",
    "    ax[0,2].set_title(f\"gnomAD (n={scoreset.sample_assignments[:,2].sum():,d})\\nprior {summary['prior']:.3f}\")\n",
    "    return fig\n",
    "\n",
    "def sample_density(x, fits, sampleNum):\n",
    "    _density = np.stack([density_utils.joint_densities(x, _fit['fit']['component_params'],_fit['fit']['weights'][sampleNum])\n",
    "                        for _fit in fits])\n",
    "    density = np.full(_density.shape,np.nan)\n",
    "    for fitIdx,fit in enumerate(fits):\n",
    "        fit_xmin,fit_xmax = fit['fit']['xlims']\n",
    "        mask = (x >= fit_xmin) & (x <= fit_xmax)\n",
    "        density[fitIdx,:,mask] = _density[fitIdx,:,mask]\n",
    "    return density\n",
    "\n",
    "def add_thresholds(tauP, tauB, ax):\n",
    "    for tp,tb in zip(tauP,tauB):\n",
    "        ax.axhline(tp,color='red',linestyle='--',alpha=0.5)\n",
    "        ax.axhline(tb,color='blue',linestyle='--',alpha=0.5)\n",
    "\n",
    "def plot_summary(scoreset: Scoreset, fits: List[Dict], summary:Dict, score_range, log_fp, log_fb):\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "    log_lr_plus = log_fp - log_fb\n",
    "    llr_curves = np.nanpercentile(np.array(log_lr_plus),[5,50,95],axis=0)\n",
    "    labels = ['5th percentile','Median','95th percentile']\n",
    "    for i,c in enumerate(['red','black','blue']):\n",
    "        ax.plot(score_range,llr_curves[i],color=c,label=labels[i])\n",
    "    point_values = sorted(list(set([abs(int(k)) for k in summary['point_ranges'].keys()])))\n",
    "    tauP,tauB = list(map(np.log, thresholds_from_prior(summary['prior'],point_values)) )\n",
    "    priors = np.percentile(np.array(summary['priors']),[5,50,95])\n",
    "    ax.set_title(f\"Prior: {priors[1]:.3f} ({priors[0]:.3f}-{priors[2]:.3f})\")\n",
    "    add_thresholds(tauP, tauB, ax)\n",
    "    ax.set_xlabel(\"Score\")\n",
    "    ax.set_ylabel(\"Log LR+\")\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12d6613e-55dd-4506-9878-bf33b490799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "urgent_datasets=(\n",
    "  'XRCC2_unpublished',\n",
    "  'VHL_Buckley_2024',\n",
    "  # 'F9_Popp_2025_heavy_chain',\n",
    "  # 'F9_Popp_2025_carboxy_F9_specific',\n",
    "  # 'BRCA2_Sahu_2023_exon13_SGE',\n",
    "  'BARD1_unpublished'\n",
    ")\n",
    "\n",
    "constrained = True\n",
    "\n",
    "save_dir = f'/data/ross/assay_calibration/point_assignments/{\"un\" if not constrained else \"\"}constrained_pngs'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "if constrained:\n",
    "    results_name = 'initial_datasets_results_1000bootstraps_100fits'\n",
    "    with gzip.open(f'/data/ross/assay_calibration/{results_name}.json.gz', 'rt', encoding='utf-8') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    results_name = 'clinvar_circ_datasets_results_1000bootstraps_100fits'\n",
    "    with gzip.open(f'/data/ross/assay_calibration/{results_name}.json.gz', 'rt', encoding='utf-8') as f:\n",
    "        results = {**results, **json.load(f)}\n",
    "\n",
    "else:\n",
    "    results_name = 'unconstrained_rerun_initial_datasets_results_1000bootstraps_100fits'\n",
    "    with gzip.open(f'/data/ross/assay_calibration/{results_name}.json.gz', 'rt', encoding='utf-8') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "\n",
    "dataset = 'VHL_Buckley_2024'\n",
    "save_dir = '/data/ross/assay_calibration/point_assignments'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "save_filepath = f'{save_dir}/{dataset}'\n",
    "\n",
    "dataset_f = f\"/data/ross/assay_calibration/scoresets/{dataset}.json\"\n",
    "scoreset = Scoreset.from_json(dataset_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e20f9a4-1f76-470e-b076-386cd36d4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_results = [results[dataset][key]['3c'] for key,val in results[dataset].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "612b7687-2903-4550-99f3-e4753dc42f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=72)]: Using backend LokyBackend with 72 concurrent workers.\n",
      "[Parallel(n_jobs=72)]: Done   1 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=72)]: Done  18 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=72)]: Done  37 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=72)]: Done  56 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=72)]: Done  77 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=72)]: Done  98 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=72)]: Done 121 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=72)]: Done 144 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=72)]: Done 169 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=72)]: Done 194 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=72)]: Done 221 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=72)]: Done 248 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=72)]: Done 277 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=72)]: Done 306 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=72)]: Done 337 tasks      | elapsed:   19.5s\n",
      "[Parallel(n_jobs=72)]: Done 368 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=72)]: Done 401 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=72)]: Done 434 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=72)]: Done 469 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=72)]: Done 504 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=72)]: Done 541 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=72)]: Done 578 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=72)]: Done 617 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=72)]: Done 656 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=72)]: Done 697 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=72)]: Done 738 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=72)]: Done 781 tasks      | elapsed:   43.2s\n",
      "[Parallel(n_jobs=72)]: Done 824 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=72)]: Done 958 out of 1000 | elapsed:   51.8s remaining:    2.3s\n",
      "[Parallel(n_jobs=72)]: Done 1000 out of 1000 | elapsed:   53.7s finished\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "summarize_scoreset(boot_results,scoreset,save_filepath)\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaad93ff-fe86-4993-b32e-9e25f8b2ffdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# boot_results = [results[dataset][key]['3c'] for key,val in results[dataset].items()]\n",
    "# try:\n",
    "#     summarize_scoreset(boot_results,scoreset,save_filepath)\n",
    "# except Exception as e:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d147c2f-4055-49bc-ad07-6192b42e255b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a732a-b379-4dca-8a8b-278e7c687577",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2 components: prior by em: median vs. most conservative of all boostraps, and old way in dan's paper\n",
    "most conservative thresholds\n",
    "enforce monotonicity on the point level - if goes down and back up, keep it most conservative. minimum to most extreme point\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (assay_calibration)",
   "language": "python",
   "name": "assay_calibration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
